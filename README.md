# Анализ настроений с использованием наивного байесовского классификатора
classifier_bnb.py - наивный байесовский классификатор Бернулли.  
classifier_mnb.py - мультиномиальный наивный байесовский классификатор.  
classifier_best.py - классификатор, показавший наилучшую точность на dev set (после подбора гиперпараметров и экспериментов)  

## Теоретическая часть
- Наивный байесовский классификатор, модель Бернулли  
Пусть V – множество {v1,v2,...,vM} всевозможных слов (словарь). В модели Бернулли для  
каждого класса cj рассматривается случайная M-мерная переменная (B1j,B2j,...,BMj),  
компоненты которой независимы, i-ая компонента соответствует vi (i-ому слову словаря) и  
имеет распределение Бернулли с вероятностью успеха pij. Другими словами, для каждого  
класса cj у нас имеется свой набор из M несимметричных монет. Чтобы сгенерировать  
документ (множество слов) из класса cj, нужно подбросить все эти монеты и выбрать из  
словаря слова, соответствующие монетам, на которых выпал орел. Документы,  
отличающиеся только порядком слов или их частотами, считаются одинаковыми.  
В каждом из следующих вопросов выпишите сначала формулу в общем виде, а затем ее  
оценку на обучающей выборке с использованием аддитивного сглаживания (сглаживания  
Лапласа).  
1) Чему равна вероятность P(vi d | d cj) встретить i-ое слово ∈ ∈ из словаря в случайном  
документе класса cj?  
2) Вывести P(d=(k1,k2,...,kM) | d∈cj) – вероятность того, что случайный документ d,  
принадлежащий классу cj, будет состоять из k1,k2,...,kM вхождений слов v1,v2,...,vM? Для  
вывода использовать “наивное” предположение о независимости признаков.  
3) Вывести вероятность P(cj | d), что данный документ принадлежит классу cj. Для вывода  
использовать формулу Байеса.  
4) Какой класс cj будет будет выдан для документа d классификатором, если предположить,  
что P(cj) и P(d | cj) заданы? Как можно оценить вероятность ошибки?  

- Мультиномиальный наивный байесовский классификатор  
В мультиномиальной модели для каждого класса cj рассматривается случайная переменная  
W с категориальным распределением Cat(r1j,..., rMj) (кубик с M гранями, вероятность  
выпадения i-ой грани – rij) и случайная переменная N с некоторым распределением P(N),  
N=1..inf. Для генерации документа вначале сэмплируется его длина n~P(N), затем n раз  
сэмплируется очередное слово w~Cat(r1j,..., rMj): n раз бросаем один и тот же  
несимметричный кубик с M гранями. Мы будем предполагать, что длина документа не  
зависит от класса: P(N|cj)=P(N) – в этом случае при построении байесовского  
классификатора ее можно игнорировать (как мы это делаем с вероятностью документа  
P(d)). Документы, отличающиеся только порядком слов, считаются одинаковыми.  
a)–d) Те же вопросы, что и для модели Бернулли.  

## Практическая часть  
- Реализовать наивный байесовский классификатор Бернулли и мультиномиальный
наивный байесовский классификатор. В качестве метрики для сравнения
использовать точность (accuracy) – процент правильно классифицированных примеров из
тестовой выборки. Сравнить точность на train/dev/test частях.
1) Загрузить обучающую выборку в 2 списка – позитивные и негативные отзывы. Чему
равна минимальная, максимальная, средняя, медианная длина (в символах) позитивных /
негативных отзывов?
2) Сделать предобработку. Перевести отзывы в нижний регистр. Вставить пробелы вокруг
всех символов, не являющихся цифрами или буквами. Учитывайте, что в отзывах
встречаются не только буквы латинского алфавита (например, слово cliché может быть
хорошим признаком отрицательного отзыва, поэтому с ним нужно обходиться аккуратно).
3) Сделать токенизацию – то есть представить каждый отзыв в виде списка токенов (слов,
чисел, знаков пунктуации). Каждый токен станет элементом словаря. При токенизации
учитывайте, что в текстах знаки пунктуации приклеиваются к предшествующему слову (не
отделяются пробелом). Однако, если предобработка выполнена правильно, это уже не
проблема. Предобработку и токенизацию полезно выделить в отдельные функции, т.к. они
понадобятся и при обработке тестовой выборки. Почему важно, чтобы тестовая и
обучающая выборка обрабатывались одинаково?
4) Построить 2 Питоновских словаря слово→частота с частотами каждого слов в
позитивных и негативных отзывах. Для позитивных и негативных отзывов распечатайте по
30 самых частотных слов и их частоты. Распечатайте 30 слов с максимальными и 30 слов с
минимальными наивными байесовскими весами (наивным байесовским весом слова будем
называть log [P(w|pos) / P(w|neg)] ), сами веса, а также абсолютные частоты этих слов в
позитивном и негативном классах. Результаты приведите в виде таблицы. Какие слова из
полученных списков кажутся позитивно/негативно окрашенными, но имеют низкий вес?
5) Используя формулы из Теоретической части реализовать байесовские классификаторы.
Обучить классификаторы на обучающей выборке и разметить с их помощью тестовую
выборку. Сколько времени обучается классификаторы и сколько времени уходит на
обработку тестовой выборки? Чему равна точность классификаторов на обучающей,
валидационной и тестовой выборках? Результаты приведите в виде таблицы. Как вы
думаете, с чем связана разная точность на обучающей и валидационной выборках? А на
валидационной и тестовой выборках?
